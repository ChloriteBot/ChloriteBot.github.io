---
layout: post
title:  "美团店铺评论爬虫"
subtitle: "一整个寒假就鼓捣一个这。高估自己了"
date:   2021-02-26 23:07:15
tags: Code
color: 'rgb(51,103,116)'
cover: '/assets/210226.png'
comments: true
---

怪无聊的，分享一下我的爬虫代码吧。用来爬取美团评论。

# 链接解析

![image-20210131142155757.png](https://i.loli.net/2021/02/26/EcsXCyoeMdnQHxK.png)

就是普通的一个页面，不想写字了，看图吧。

# 代码

## 祖传开头

```python
import requests
import json
import time
import csv
def getHTMLText(url):
    try:
        headers = {
   			'user-agent': '去百度一些，来回换',
    		'accept': 'application/json, text/javascript, */*; q=0.01',
    		'cookie': '登录后在自己浏览器里复制',
        }
        response = requests.get(url, headers=headers)
        return response.text
    except:
        return "产生异常"
```

## 爬餐厅，写入csv

```python
r_file_name = 'C:/Desktop/bsnInfo.csv'
page_count = 10
with open (r_file_name, "w", newline='',encoding='utf8') as f :
    f_csv = csv.writer(f)
    f_csv.writerow(['poiId', 'title', 'avgScore', 'allCommentNum', 'address', 'avgPrice'])
    for page_num in range(1, page_count + 1):
        url = f"按照需要替换"
        text = getHTMLText(url)
        jsonBody = json.loads(text.encode('utf-8'))
        r_datas = jsonBody['data']['poiInfos']
        for r_data in r_datas:
            f_csv.writerow([r_data['poiId'],r_data['title'],r_data['avgScore'],r_data['allCommentNum'],
                           r_data['address'],r_data['avgPrice']])
```

## 写完餐厅csv，读店铺id，准备爬评论

```python
r_file_name = 'C:/Desktop/bsnInfo.csv'
csv_reader = csv.reader(open(r_file_name, encoding='utf-8'))
next(csv_reader)
id_and_pn_list = []
for row in csv_reader:
    id_and_pn_list.append((row[0],row[1],int(row[3])))
```

## 爬评论！

```python
import random

for i,title,pn in id_and_pn_list:
    rev_file_name = f'C:/Desktop/{title}.csv'

    with open (rev_file_name, "w", newline='',encoding='utf8') as f :
        f_csv = csv.writer(f)
        f_csv.writerow(['id','给分','评论'])

        pn = pn//10 if pn%10 == 0 else pn//10 + 1
        print(pn)
        for c_pn in range(int(pn/2)):
            print(c_pn)
            url = f"https://www.meituan.com/meishi/api/poi/getMerchantComment?uuid="换cookie"&platform=1&partner=126&originUrl=https%3A%2F%2Fwww.meituan.com%2Fmeishi%2F{i}%2F&riskLevel=1&optimusCode=10&id={i}&userId=640922740&offset={c_pn*10}&pageSize=10&sortType=1"
            print(url)
            text = getHTMLText(url)
            time.sleep(5)

            jsonBody = json.loads(text.encode('utf-8'))
            rev_datas = jsonBody['data']['comments']
            for rev_data in rev_datas:

                f_csv.writerow([rev_data['userId'],rev_data['star'],rev_data['comment']])
```

爬完这么一遍，已经刻进DNA里了。现在看见就有点反胃，不想再看了。

也不知道未来的我还能不能看懂，但我真是不想再加批注了。突然明白CSDN上为什么通常只有代码没有注释了。当我学会以后，我也开始觉得写注释没有什么必要了。（主要还是懒

